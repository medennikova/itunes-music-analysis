{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iTunes music library analysis: Data preparation\n",
    "\n",
    "This is the first post in a series of posts devoted to analysis of iTunes music library using Scikit-Learn tools.   \n",
    "This notebook covers data gathering, preparation and cleaning of the datasets I'm going to use in my analysis.\n",
    "For the summary of this analysis, its goals, methods and installation notes please go to [link]. \n",
    "\n",
    "## Preliminaries\n",
    "\n",
    "One of the main goals of this analysis is to explore the basics of Scikit-Learn tools. **[Scikit-Learn](http://scikit-learn.org)** is a popular Python package designed to give access to well-known machine learning algorithms within Python code.\n",
    "\n",
    "Scikit-Learn is built upon Python's **[NumPy (Numerical Python)](http://www.numpy.org/)** and **[SciPy (Scientific Python)](http://scipy.org/)** libraries, which enable efficient in-core numerical and scientific computation within Python. \n",
    "\n",
    "I also use **[pandas](http://pandas.pydata.org/)** library in my analysis. Pandas is a Python package providing fast, flexible, and expressive data structures. It is a fundamental high-level building block for doing practical, real world data analysis in Python.\n",
    "\n",
    "**[Matplotlib](http://matplotlib.org/)** and **[Seaborn](https://stanford.edu/~mwaskom/software/seaborn/)** are used for data visualization. \n",
    "\n",
    "The hero and the foundation of my analysis is the **[Echo Nest API](http://the.echonest.com/)**, which provides broad and deep data on millions of artists and songs. **[Pyechonest](https://github.com/echonest/pyechonest)** is an open source Python library for the Echo Nest API that I use in this analysis. To use The Echo Nest API, an API key is required. More about the API key [here](http://developer.echonest.com/raw_tutorials/register.html).\n",
    "\n",
    "I start with importing all modules. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: replace the API key with MY_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# set seaborn plot defaults\n",
    "import seaborn as sns; sns.set(palette=\"husl\")\n",
    "\n",
    "# import pyechonest\n",
    "from pyechonest import config\n",
    "# pass my API key\n",
    "config.ECHO_NEST_API_KEY=\"1RNDIJ5SITBKZFDCT\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Data preparation\n",
    "\n",
    "In this analysis I'm dealing with classification problem. I'm interested in three classes of music (\"cycling\", \"yoga\", \"ballet\") and I want to find tracks in my iTunes music library that fit these classes. To solve that problem I use *machine learning classification algorithms*.  \n",
    "\n",
    "Machine learning is about creating models from data: a model learns from training data (data with class labels), and can be used to predict the result of test data (data without class labels).\n",
    "\n",
    "For the analysis I use two datasets:\n",
    "1. iTunes music library serves me as a *test dataset*;\n",
    "2. For the *training dataset* I made a csv file ('./labeled_tracks.csv') with hand picked tracks outside of my iTunes library. I labeled each track with one of the three classes: \"cycling\", \"yoga\", \"ballet\". \n",
    "\n",
    "iTunes library files track the media in iTunes. The iTunes library file, a file called iTunes Music Library.xml, is created automatically when you launch iTunes. 'iTunes Music Library.xml' contains information that's stored in the iTunes database of the songs in the library. On Mac OS X, it can be found in the directory 'Users/username/Music/iTunes'. More information about iTunes library files can be found [here](https://support.apple.com/en-us/HT201610).\n",
    "\n",
    "For both datasets I use a sqlite3 database (DB) and use the **[sqlitedict](https://github.com/piskvorky/sqlitedict)** library to access it. sqlitedict is a lightweight wrapper around Python's sqlite3 DB with a simple, Pythonic dict-like interface. For this particular problem I think using a DB is more convenient than a CSV or XML file. \n",
    "\n",
    "### Test dataset\n",
    "I will start by processing the test data.  \n",
    "\n",
    "To parse iTunes xml file I use **[pyItunes](https://github.com/liamks/pyitunes)** module, which makes it easier to access tracks in the xml file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_itunes_track_data(song):\n",
    "    \"\"\"check the validity of the track, \n",
    "    exclude podcasts and tracks \n",
    "    missing artist's name.\n",
    "    \"\"\"\n",
    "    if (song.genre == 'Podcast' or \n",
    "        song.genre == u'iTunes U' or \n",
    "        song.kind != 'MPEG audio file' or \n",
    "        not song.artist): \n",
    "        return None \n",
    "    else:\n",
    "        return song.name, song.artist\n",
    "\n",
    "def parse_itunes_xml(db, xml_file):\n",
    "    \"\"\"parse xml, get song's title\n",
    "    and artist's name, save to a database.\n",
    "    \"\"\"\n",
    "    from pyItunes import Library\n",
    "    l = Library(xml_file)\n",
    "    \n",
    "    for id, song in l.songs.items():\n",
    "        try:\n",
    "            song_title, artist = get_itunes_track_data(song)\n",
    "            if not db.get(song_title):\n",
    "                db[song_title] = {'artist' : artist}\n",
    "        except TypeError as e:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sqlitedict import SqliteDict\n",
    "\n",
    "# path to the iTunes xml file\n",
    "xml_file = 'iTunes Music Library copy.xml'\n",
    "\n",
    "# create a DB to store data from iTunes library\n",
    "test_db = SqliteDict('./itunes_tracks', \n",
    "                     autocommit=True)\n",
    "\n",
    "# call parse_itunes_xml function and \n",
    "# write the data into the DB.\n",
    "# TODO: uncomment\n",
    "parse_itunes_xml(test_db, xml_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DB contains 554 tracks.\n",
      "Example of values for the track \"Moon river\": \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acousticness': 0.853775,\n",
       " 'artist': 'Andrea Ross',\n",
       " 'danceability': 0.204634,\n",
       " 'energy': 0.248916,\n",
       " 'instrumentalness': 0.00198,\n",
       " 'key': 8,\n",
       " 'loudness': -11.155,\n",
       " 'mode': 1,\n",
       " 'speechiness': 0.03465,\n",
       " 'tempo': 155.866,\n",
       " 'time_signature': 3,\n",
       " 'valence': 0.185901}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the resulting DB\n",
    "print (\"The DB contains {} tracks.\"\n",
    "       .format(len(test_db)))\n",
    "print \"Example of values for the track \\\"Moon river\\\": \"\n",
    "test_db['Moon river']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to get song attributes from the Echo Nest API.  \n",
    "\n",
    "In the analysis I use the following track attributes:\n",
    "\n",
    "* **Acousticness** represents the likelihood a recording was created by solely acoustic means such as voice and acoustic instruments as opposed to electronically such as with synthesized, amplified, or effected instruments;\n",
    "* **Danceability** describes how suitable a track is for dancing using a number of musical elements (tempo, rhythm stability, beat strength, and overall regularity);\n",
    "* **Energy** represents a perceptual measure of intensity and powerful activity released throughout the track;\n",
    "* **Instrumentalnes** is a measure of how likely a song is to be instrumental;\n",
    "* **Key** identifies the tonic triad, the chord, major or minor;\n",
    "* **Loudness** measureas the overall loudness of a track in decibels (dB);\n",
    "* **Mode** indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived;\n",
    "* **Speechiness** detects the presence of spoken words in a track;\n",
    "* **Tempo** is the speed or pace of a given piece (in beats per minute);\n",
    "* **Time signature** specifies how many beats are in each bar (or measure);\n",
    "* **Valence** describes the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g., happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).\n",
    "\n",
    "Using the Echo Nest Python library Pyechonest is super easy and straighforward.  \n",
    "\n",
    "The Echo Nest database doesn't provide data for every artist or song. I handle missing items with a \"try-except\" block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_track_attr_data(artist_name, song_title):\n",
    "    \"\"\"Get track attributes data from \n",
    "    the Echo Nest database.\n",
    "    \"\"\"\n",
    "    from pyechonest import song\n",
    "    try: \n",
    "        result = song.search(artist=artist_name, \n",
    "                             title=song_title)\n",
    "        song_result = result[0]\n",
    "        song_data = song_result.audio_summary\n",
    "        \n",
    "        # returns a dictionary of song attributes\n",
    "        return song_data\n",
    "    \n",
    "    except IndexError as e:\n",
    "        print 'No data for the song', song_title\n",
    "        return None\n",
    "    \n",
    "def pick_track_attr(song_data):\n",
    "    \"\"\"Pick required track attributes from a dict\n",
    "    I got from the Echo Nest library.\n",
    "    \"\"\"\n",
    "    song_val = {'time_signature' : song_data['time_signature'],\n",
    "                'energy' : song_data['energy'],\n",
    "                'tempo' : song_data['tempo'], \n",
    "                'speechiness' : song_data['speechiness'],\n",
    "                'acousticness' : song_data['acousticness'], \n",
    "                'danceability' : song_data['danceability'],\n",
    "                'instrumentalness' : song_data['instrumentalness'],\n",
    "                'key' : song_data['key'],\n",
    "                'loudness' : song_data['loudness'],\n",
    "                'valence' : song_data['valence'],\n",
    "                'mode' : song_data['mode']}\n",
    "    \n",
    "    return song_val\n",
    "         \n",
    "def set_echonest_attributes(db):\n",
    "    \"\"\"Look for new tracks in the DB, request  \n",
    "    track attributes from the Echo Nest library \n",
    "    and save to the db.\n",
    "    \"\"\"\n",
    "    from time import sleep\n",
    "\n",
    "    for song_title, value in db.iteritems():\n",
    "        # Check if the attributes have been already added\n",
    "        if value.get('tempo') or value.get('No_data'): \n",
    "            pass\n",
    "        else:\n",
    "            song_data = get_track_attr_data(value['artist'], \n",
    "                                            song_title)\n",
    "            \n",
    "            # If the song is in the Echo Nest DB, \n",
    "            # I add the data to the DB.\n",
    "            if song_data:\n",
    "                song_val = pick_track_attr(song_data)\n",
    "                value.update(song_val)\n",
    "                db[song_title] = value\n",
    "            # If not, I add 'No_data' key to the song. \n",
    "            else:\n",
    "                song_val = {'No_data' : True}\n",
    "                value.update(song_val)\n",
    "                db[song_title] = value\n",
    "            # Echo Nest limits number of requests to 20 per minute\n",
    "            sleep(8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# call set_echonest_attributes function and \n",
    "# write the Echo Nest data into the iTunes DB.\n",
    "# TODO: uncomment\n",
    "# set_echonest_attributes(test_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DB contains 554 tracks.\n",
      "Example of values for the track \"Moon river\":\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acousticness': 0.853775,\n",
       " 'artist': 'Andrea Ross',\n",
       " 'danceability': 0.204634,\n",
       " 'energy': 0.248916,\n",
       " 'instrumentalness': 0.00198,\n",
       " 'key': 8,\n",
       " 'loudness': -11.155,\n",
       " 'mode': 1,\n",
       " 'speechiness': 0.03465,\n",
       " 'tempo': 155.866,\n",
       " 'time_signature': 3,\n",
       " 'valence': 0.185901}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the resulting DB\n",
    "print (\"The DB contains {} tracks.\"\n",
    "       .format(len(test_db)))\n",
    "print \"Example of values for the track \\\"Moon river\\\":\"\n",
    "test_db['Moon river']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training dataset\n",
    "\n",
    "For the training dataset I made a csv file ('./labeled_tracks.csv') with hand picked tracks and labaled each track with one of the three classes: \"cycling\", \"yoga\", \"ballet\".\n",
    "\n",
    "I use pandas read_csv function to read the csv file and write it into the sqlite3 dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_tracks_from_csv(csv_file, db):\n",
    "    \"\"\"Transform the csv file into a pandas dataframe,\n",
    "    save data to a new DB for training data.\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(csv_file, index_col='song', \n",
    "                       encoding='utf_8', header=0)\n",
    "    for item in data.index:\n",
    "        artist = data.loc[item]['artist']\n",
    "        # category column contains class label\n",
    "        song_cat = data.loc[item]['category']\n",
    "        if not db.get(item):\n",
    "            db[item] = {'artist' : artist, 'category' : song_cat}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path to the csv file\n",
    "# csv_file = './labeled_tracks.csv'\n",
    "\n",
    "#TODO: change name of the db to './labeled_tracks'\n",
    "# create a DB to store training data from the csv file\n",
    "train_db = SqliteDict('./chosen_tracks', autocommit=True)\n",
    "\n",
    "# call parse_tracks_from_csv function\n",
    "# parse_tracks_from_csv(csv_file, train_db)\n",
    "\n",
    "# write the Echo Nest data into the training DB\n",
    "#TODO: uncomment\n",
    "# set_echonest_attributes(train_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DB contains 128 tracks.\n",
      "Example of values for the track \"Five Seconds\":\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acousticness': 0.001899,\n",
       " 'artist': u'Twin Shadow',\n",
       " 'category': u'cycling',\n",
       " 'danceability': 0.467563,\n",
       " 'energy': 0.879714,\n",
       " 'instrumentalness': 0.007045,\n",
       " 'key': 1,\n",
       " 'loudness': -5.086,\n",
       " 'mode': 1,\n",
       " 'speechiness': 0.057028,\n",
       " 'tempo': 176.972,\n",
       " 'time_signature': 4,\n",
       " 'valence': 0.64461}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the resulting DB\n",
    "print (\"The DB contains {} tracks.\"\n",
    "       .format(len(train_db)))\n",
    "print \"Example of values for the track \\\"Five Seconds\\\":\"\n",
    "train_db['Five Seconds']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data overview  \n",
    "  \n",
    "I have two DBs with track attributes data from the Echo Nest API. Next step is to read in data from both DBs and take a look at what I'm working with.\n",
    "\n",
    "I transform DBs into pandas dataframes (DF), which one can think of as an Excel-like table of values. Dataframes have various methods that can be called to easily learn about the data contained in them. I leave in the DF only tracks with  attributes data for further analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_db_in_pandas(db):\n",
    "    \"\"\" Read the DB and return a DF.\n",
    "    \"\"\"\n",
    "    # transpose data to have tracks as rows\n",
    "    df = pd.DataFrame(dict(db)).T\n",
    "    \n",
    "    # remove rows with no data for a song\n",
    "    df_clean = df[df['No_data'] != 1]\n",
    "    \n",
    "    # convert columns into numbers\n",
    "    df_clean = df_clean.convert_objects(convert_numeric=True)\n",
    "    \n",
    "    # convert index into a column\n",
    "    df_clean.reset_index(level=0, inplace=True)\n",
    "    df_clean.rename(columns = {'index': 'song_title'}, \n",
    "                    inplace=True)\n",
    "\n",
    "    # remove the 'No_data' column\n",
    "    df_clean.drop('No_data', 1, \n",
    "                  inplace=True)\n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a df with training data\n",
    "train_df = read_db_in_pandas(train_db)\n",
    "\n",
    "# format floating point numbers \n",
    "# within pandas data structures\n",
    "pd.set_option('float_format', '{:.2f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rearrange the order of columns \n",
    "cols = train_df.columns.tolist()\n",
    "cols = cols[0:1] + cols[2:4] + cols[1:2] + cols[4:]\n",
    "train_df = train_df.ix[:, cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 128 tracks in the dataset.\n",
      "37 tracks have no data available in the Echo Nest API.\n",
      "We are left with 91 tracks to use as training data.\n",
      "\n",
      "Below is a random sample of the dataset.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_title</th>\n",
       "      <th>artist</th>\n",
       "      <th>category</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>I</td>\n",
       "      <td>Benn Jordan</td>\n",
       "      <td>yoga</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.83</td>\n",
       "      <td>10</td>\n",
       "      <td>-18.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>144.31</td>\n",
       "      <td>4</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>TV Queen</td>\n",
       "      <td>Wild nothing</td>\n",
       "      <td>cycling</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.21</td>\n",
       "      <td>9</td>\n",
       "      <td>-5.90</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>134.95</td>\n",
       "      <td>4</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Lounge Me</td>\n",
       "      <td>Sunsphere</td>\n",
       "      <td>focus</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.89</td>\n",
       "      <td>10</td>\n",
       "      <td>-11.41</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>97.97</td>\n",
       "      <td>4</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>In the fog III</td>\n",
       "      <td>Tim Hecker</td>\n",
       "      <td>focus</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.94</td>\n",
       "      <td>5</td>\n",
       "      <td>-9.03</td>\n",
       "      <td>0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>118.82</td>\n",
       "      <td>4</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        song_title        artist category  acousticness  danceability  energy  \\\n",
       "36               I   Benn Jordan     yoga          0.75          0.27    0.35   \n",
       "71        TV Queen  Wild nothing  cycling          0.00          0.44    0.86   \n",
       "47       Lounge Me     Sunsphere    focus          0.01          0.68    0.64   \n",
       "38  In the fog III    Tim Hecker    focus          0.46          0.17    0.32   \n",
       "\n",
       "    instrumentalness  key  loudness  mode  speechiness  tempo  time_signature  \\\n",
       "36              0.83   10    -18.87     1         0.03 144.31               4   \n",
       "71              0.21    9     -5.90     1         0.05 134.95               4   \n",
       "47              0.89   10    -11.41     0         0.05  97.97               4   \n",
       "38              0.94    5     -9.03     0         0.04 118.82               4   \n",
       "\n",
       "    valence  \n",
       "36     0.39  \n",
       "71     0.72  \n",
       "47     0.54  \n",
       "38     0.04  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (\"There are {0} tracks in the dataset.\"\n",
    "       .format(len(train_db)))\n",
    "print (\"{0} tracks have no data available \"\n",
    "       \"in the Echo Nest API.\"\n",
    "       .format(len(train_db) - len(train_df)))\n",
    "print (\"We are left with {0} tracks to use as training data.\"\n",
    "       .format(len(train_df)))\n",
    "print \"\\nBelow is a random sample of the dataset.\"\n",
    "train_df.sample(n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracks in the dataset belong to 3 categories: cycling, focus, yoga.\n",
      "26 tracks represent 'cycling' category.\n",
      "34 tracks represent 'focus' category.\n",
      "31 tracks represent 'yoga' category.\n"
     ]
    }
   ],
   "source": [
    "# list of categories\n",
    "categories = list(pd.unique(train_df.category.ravel()))\n",
    "\n",
    "print (\"Tracks in the dataset belong \" \n",
    "       \"to {} categories: {}.\"\n",
    "       .format(len(categories), \", \".join(categories)))\n",
    "\n",
    "# count tracks in each category\n",
    "cat_count = pd.value_counts(train_df.category.ravel())\n",
    "\n",
    "# print categories\n",
    "for category in categories:\n",
    "    print (\"{} tracks represent \\'{}\\' category.\"\n",
    "           .format(cat_count[category], category))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data overview\n",
    "\n",
    "Now I move on to the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 554 tracks in the dataset.\n",
      "223 tracks have no data available in the Echo Nest API.\n",
      "We are left with 331 tracks to use as a test set.\n",
      "\n",
      "Summary statistics: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_title</th>\n",
       "      <th>artist</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>White Rain</td>\n",
       "      <td>Junip</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.77</td>\n",
       "      <td>5</td>\n",
       "      <td>-11.42</td>\n",
       "      <td>0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>149.55</td>\n",
       "      <td>4</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>Nanny Nanny Boo Boo</td>\n",
       "      <td>Le Tigre</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.55</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>126.05</td>\n",
       "      <td>4</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>LIAR LIAR</td>\n",
       "      <td>CASTAWAYS</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.78</td>\n",
       "      <td>7</td>\n",
       "      <td>-13.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>146.01</td>\n",
       "      <td>4</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>Yeti's Lament</td>\n",
       "      <td>Berry Weight</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.88</td>\n",
       "      <td>4</td>\n",
       "      <td>-8.46</td>\n",
       "      <td>0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>90.07</td>\n",
       "      <td>4</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              song_title        artist  acousticness  danceability  energy  \\\n",
       "308           White Rain         Junip          0.15          0.58    0.58   \n",
       "175  Nanny Nanny Boo Boo      Le Tigre          0.04          0.85    0.89   \n",
       "133            LIAR LIAR     CASTAWAYS          0.83          0.47    0.48   \n",
       "315        Yeti's Lament  Berry Weight          0.84          0.55    0.47   \n",
       "\n",
       "     instrumentalness  key  loudness  mode  speechiness  tempo  \\\n",
       "308              0.77    5    -11.42     0         0.03 149.55   \n",
       "175              0.00    1     -3.55     1         0.05 126.05   \n",
       "133              0.78    7    -13.88     0         0.03 146.01   \n",
       "315              0.88    4     -8.46     0         0.03  90.07   \n",
       "\n",
       "     time_signature  valence  \n",
       "308               4     0.61  \n",
       "175               4     0.81  \n",
       "133               4     0.81  \n",
       "315               4     0.23  "
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a df with test data\n",
    "test_df = read_db_in_pandas(test_db)\n",
    "\n",
    "# rearrange the order of columns \n",
    "test_cols = test_df.columns.tolist()\n",
    "test_cols = test_cols[0:1] + test_cols[2:3] + test_cols[1:2] + test_cols[3:]\n",
    "test_df = test_df.ix[:, test_cols]\n",
    "\n",
    "print (\"There are {0} tracks in the dataset.\"\n",
    "       .format(len(test_db)))\n",
    "print (\"{0} tracks have no data available \" \n",
    "       \"in the Echo Nest API.\"\n",
    "       .format(len(test_db) - len(test_df)))\n",
    "print (\"We are left with {0} tracks to use as a test set.\"\n",
    "       .format(len(test_df)))\n",
    "print \"\\nBelow is a random sample of the dataset.\"\n",
    "test_df.sample(n=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "In this notebook I described data gathering and cleaning process for further analysis. I parsed iTunes music library xml file to create a database of tracks for the test dataset. I also transformed the csv file with labeled tracks into a sqlite3 database for the training set. Using the Echo Nest API I got track attributes for both sets.\n",
    "\n",
    "As a result of the above manipulations I have two pandas dataframes: \n",
    "* train dataframe contains 91 labeled tracks in three classes — \"cycling\", \"yoga\", \"ballet\";\n",
    "* test dataframe contains 331 non-labeled tracks. \n",
    "\n",
    "The next step in my analysis is to visualize both datasets and examine track attributes. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
