{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Machine Learning for music playlists: Data preparation\n",
    "\n",
    "This is the first post in a series of posts devoted to building music playlists with Scikit-Learn tools.   \n",
    "This notebook covers data gathering and preparation and cleaning of the datasets I'm going to use in my analysis.\n",
    "For the overview of this analysis, its goals, methods, and installation notes please go to [00_Overview](http://localhost:8888/notebooks/00_Overview.ipynb). \n",
    "\n",
    "#### Contents of the notebook\n",
    "* [Machine Learning Intro](http://localhost:8888/notebooks/01_Data_preparation.ipynb#Machine-Learning-Intro)\n",
    "* [Preliminaries](http://localhost:8888/notebooks/01_Data_preparation.ipynb#Preliminaries)\n",
    "* [Data preparation](http://localhost:8888/notebooks/01_Data_preparation.ipynb#Data-preparation)\n",
    "* [Data overview](http://localhost:8888/notebooks/01_Data_preparation.ipynb#Data-overview)\n",
    "* [Summary](http://localhost:8888/notebooks/01_Data_preparation.ipynb#Summary)\n",
    "\n",
    "## Machine Learning Intro\n",
    "In this analysis I'm interested in three classes of music (\"cycling\", \"ballet\", \"yoga\") and I want to find tracks in my iTunes music library that fit these classes. This is a multiclass classification problem. Classification is the task of predicting the value of a categorical variable given some input variables (the features). \n",
    "\n",
    "To solve that problem I use *supervised machine learning classification algorithms*.  \n",
    "\n",
    "Supervised machine learning is about creating models from data: a model learns from training data (data with class labels), and can be used to predict the result of test data (data without class labels). Thus the task of supervised learning is to construct an estimator which is able to predict the label of an object given the set of features. One can also think of classification as a function estimation problem where the function that we want to estimate separates the classes.\n",
    "\n",
    "## Preliminaries\n",
    "One of the main goals of this analysis is to explore the basics of Scikit-Learn tools. **[Scikit-Learn](http://scikit-learn.org)** is a popular Python package designed to give access to well-known machine learning algorithms within Python code. \n",
    "\n",
    "Scikit-Learn is built upon Python's **[NumPy (Numerical Python)](http://www.numpy.org/)** and **[SciPy (Scientific Python)](http://scipy.org/)** libraries, which enable efficient in-core numerical and scientific computation within Python. \n",
    "\n",
    "I also use **[pandas](http://pandas.pydata.org/)** library in my analysis. Pandas is a Python package providing fast, flexible, and expressive data structures. It is a fundamental high-level building block for doing practical, real world data analysis in Python.\n",
    "\n",
    "The hero and the foundation of my analysis is the **[Echo Nest API](http://the.echonest.com/)**, which provides broad and deep data on millions of artists and songs. **[Pyechonest](https://github.com/echonest/pyechonest)** is an open source Python library for the Echo Nest API that I use in this analysis. To use The Echo Nest API, an API key is required. More about the API key [here](http://developer.echonest.com/raw_tutorials/register.html).\n",
    "\n",
    "In the analysis I use the following track attributes, which are available through the Echo Nest API:\n",
    "\n",
    "* **Acousticness** represents the likelihood a recording was created by solely acoustic means such as voice and acoustic instruments as opposed to electronically such as with synthesized, amplified, or effected instruments;\n",
    "* **Danceability** describes how suitable a track is for dancing using a number of musical elements (tempo, rhythm stability, beat strength, and overall regularity);\n",
    "* **Energy** represents a perceptual measure of intensity and powerful activity released throughout the track;\n",
    "* **Instrumentalnes** is a measure of how likely a song is to be instrumental;\n",
    "* **Key** identifies the tonic triad, the chord, major or minor. Key signatures start at 0 (C) and ascend the chromatic scale;\n",
    "* **Loudness** measures the overall loudness of a track in decibels (dB);\n",
    "* **Mode** indicates the modality (major (1) or minor (0)) of a track, the type of scale from which its melodic content is derived;\n",
    "* **Speechiness** detects the presence of spoken words in a track;\n",
    "* **Tempo** is the speed or pace of a given piece (in beats per minute);\n",
    "* **Time signature** specifies how many beats are in each measure;\n",
    "* **Valence** describes the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g., happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).\n",
    "\n",
    "\n",
    "I start with importing modules required in the following notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# format floating point numbers\n",
    "# within pandas data structures\n",
    "pd.set_option('float_format', '{:.2f}'.format)\n",
    "\n",
    "# import pyechonest\n",
    "from pyechonest import config\n",
    "\n",
    "# pass my API key\n",
    "config.ECHO_NEST_API_KEY=\"1RNDIJ5SITBKZFDCT\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Data preparation\n",
    "In the analysis I use two datasets:\n",
    "1. iTunes music library serves me as a *test dataset*, or non-labeled data;\n",
    "2. For the *training dataset* I made a csv file ('./labeled_tracks.csv') with hand picked tracks outside of my iTunes library. I labeled each track with one of the three classes: \"cycling\", \"yoga\", \"ballet\". \n",
    "\n",
    "iTunes library files track the media in iTunes. The iTunes library file, a file called iTunes Music Library.xml, is created automatically when you launch iTunes. 'iTunes Music Library.xml' contains information that's stored in the iTunes database of the songs in the library. On Mac OS X, it can be found in the directory 'Users/username/Music/iTunes'. More information about iTunes library files can be found [here](https://support.apple.com/en-us/HT201610).\n",
    "\n",
    "Throughout the analysis I use pandas DataFrame (DF) data structure, which one can think of as an Excel-like table of values. DataFrames have various methods that can be called to easily learn about the data contained in them. \n",
    "\n",
    "To store data and results of my computations I use **[HDF5](http://pandas.pydata.org/pandas-docs/stable/io.html#io-hdf5)** format. HDF5 allows to treat a local file as a hash and work directly with pandas DataFrames. Very cool. It's trivial to read and write from this file using Pandas. \n",
    "### Test dataset\n",
    "I will start by processing the test data.  \n",
    "\n",
    "To parse iTunes xml file I use **[pyItunes](https://github.com/liamks/pyitunes)** module, which makes it easier to access tracks in the xml file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_itunes_track_data(song):\n",
    "    \"\"\"Check the validity of the track, \n",
    "    exclude podcasts and tracks \n",
    "    missing artist's name.\n",
    "    \"\"\"\n",
    "    if (song.genre == 'Podcast' or \n",
    "        song.genre == u'iTunes U' or \n",
    "        song.kind != 'MPEG audio file' or \n",
    "        not song.artist): \n",
    "        return None \n",
    "    else:\n",
    "        return song.name, song.artist\n",
    "\n",
    "def parse_itunes_xml(xml_file, features):\n",
    "    \"\"\"Parse xml, get song's title\n",
    "    and artist's name. Return DataFrame.\n",
    "    \"\"\"\n",
    "    from pyItunes import Library\n",
    "    l = Library(xml_file)\n",
    "    \n",
    "    # create empty df with feature names as columns\n",
    "    df = pd.DataFrame(columns=features)\n",
    "    \n",
    "    for id, song in l.songs.items():\n",
    "        try:\n",
    "            song_title, artist = get_itunes_track_data(song)\n",
    "            df = df.append({'artist' : unicode(artist), \n",
    "                            'song' : unicode(song_title)}, \n",
    "                           ignore_index=True)\n",
    "        except TypeError as e:\n",
    "            continue\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# path to the iTunes xml file (I copied it)\n",
    "xml_file = 'iTunes Music Library copy.xml'\n",
    "\n",
    "# list of features to use in the analysis\n",
    "features = ['acousticness',\n",
    "            'danceability',\n",
    "            'energy',\n",
    "            'instrumentalness',\n",
    "            'key',\n",
    "            'loudness',\n",
    "            'mode',\n",
    "            'speechiness',\n",
    "            'tempo',\n",
    "            'time_signature',\n",
    "            'valence']\n",
    "\n",
    "# create a DF for data from iTunes library\n",
    "test_data = parse_itunes_xml(xml_file, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset contains 669 tracks.\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 669 entries, 0 to 668\n",
      "Data columns (total 13 columns):\n",
      "acousticness        0 non-null object\n",
      "danceability        0 non-null object\n",
      "energy              0 non-null object\n",
      "instrumentalness    0 non-null object\n",
      "key                 0 non-null object\n",
      "loudness            0 non-null object\n",
      "mode                0 non-null object\n",
      "speechiness         0 non-null object\n",
      "tempo               0 non-null object\n",
      "time_signature      0 non-null object\n",
      "valence             0 non-null object\n",
      "artist              669 non-null object\n",
      "song                669 non-null object\n",
      "dtypes: object(13)\n",
      "memory usage: 73.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# review the result\n",
    "print (\"Test dataset contains {} tracks.\"\n",
    "       .format(len(test_data)))\n",
    "print \n",
    "print test_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 13 features, or track attributes, in the DataFrame, but only two columns have data — \"song\" and \"artist\". The next step is to get song attributes from the Echo Nest API to fill in other columns in the DF.  \n",
    "\n",
    "Using the Echo Nest Python library Pyechonest is super easy and straightforward.  \n",
    "\n",
    "The Echo Nest database doesn't provide data for every artist or song. I handle missing items with a \"try-except\" block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_track_attr_data(artist_name, song_title):\n",
    "    \"\"\"Get track attributes data from \n",
    "    the Echo Nest database.\n",
    "    \"\"\"\n",
    "    from pyechonest import song\n",
    "    try: \n",
    "        result = song.search(artist=artist_name, \n",
    "                             title=song_title)\n",
    "        song_result = result[0]\n",
    "        song_data = song_result.audio_summary\n",
    "        \n",
    "        # returns a dictionary of song attributes\n",
    "        return song_data\n",
    "    \n",
    "    except IndexError as e:\n",
    "        return None\n",
    "         \n",
    "def add_features_from_echonest(df, features):\n",
    "    \"\"\"Request track features from\n",
    "    the Echo Nest database and add to the DF.\n",
    "    Return DF.\n",
    "    \"\"\"\n",
    "    from time import sleep\n",
    "    \n",
    "    for i in df.index.tolist():\n",
    "        # Check if attributes have been already added\n",
    "        if pd.notnull(df.loc[i, 'tempo']): \n",
    "            pass\n",
    "        else:\n",
    "            song_data = get_track_attr_data(df.loc[i, 'artist'], \n",
    "                                            df.loc[i, 'song'])\n",
    "            \n",
    "            # If the song is in the Echo Nest DB, \n",
    "            # I add data to the DF.\n",
    "            if song_data:\n",
    "                for f in features:\n",
    "                    df.loc[i, f] = song_data[f]\n",
    "            # If not, I drop the track. \n",
    "            else:\n",
    "                df = df.drop(i)\n",
    "        # Echo Nest limits number of requests to 20 per minute\n",
    "        sleep(6) \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I call the function to add track features from the Echo Nest data to the DF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add features\n",
    "test_df = add_features_from_echonest(test_data, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset contains 536 tracks.\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 536 entries, 0 to 668\n",
      "Data columns (total 13 columns):\n",
      "acousticness        536 non-null float64\n",
      "danceability        536 non-null float64\n",
      "energy              536 non-null float64\n",
      "instrumentalness    536 non-null float64\n",
      "key                 536 non-null int64\n",
      "loudness            536 non-null float64\n",
      "mode                536 non-null int64\n",
      "speechiness         536 non-null float64\n",
      "tempo               536 non-null float64\n",
      "time_signature      536 non-null int64\n",
      "valence             536 non-null float64\n",
      "artist              536 non-null object\n",
      "song                536 non-null object\n",
      "dtypes: float64(8), int64(3), object(2)\n",
      "memory usage: 58.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# view the resulting DF\n",
    "print (\"Test dataset contains {} tracks.\\n\"\n",
    "       .format(len(test_df))) \n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table above gives us an overview of data in DF columns. There are 536 tracks, or rows, in the test set. We have 11 numeric features (these are the data from the Echo Nest) and 2 columns with text data. I notice, however, that all numeric features were identified as float type. I know that three features \"key\", \"mode\", and \"time_signature\" are discrete, not continuous as other features, with a limited number of values. E.g. \"time_signature\" has 4 values: 1, 3, 4 or 5. I change type of these three features to integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 536 entries, 0 to 668\n",
      "Data columns (total 13 columns):\n",
      "acousticness        536 non-null float64\n",
      "danceability        536 non-null float64\n",
      "energy              536 non-null float64\n",
      "instrumentalness    536 non-null float64\n",
      "key                 536 non-null int64\n",
      "loudness            536 non-null float64\n",
      "mode                536 non-null int64\n",
      "speechiness         536 non-null float64\n",
      "tempo               536 non-null float64\n",
      "time_signature      536 non-null int64\n",
      "valence             536 non-null float64\n",
      "artist              536 non-null object\n",
      "song                536 non-null object\n",
      "dtypes: float64(8), int64(3), object(2)\n",
      "memory usage: 58.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# change dtype to integer\n",
    "test_df[['key', 'mode', 'time_signature']] = test_df[['key', 'mode', 'time_signature']].astype(int)\n",
    "\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training dataset\n",
    "\n",
    "For the training dataset I made a csv file ('./labeled_tracks.csv') with hand picked tracks and labeled each track with one of the three classes: \"cycling\", \"ballet\", \"yoga\".\n",
    "\n",
    "I use pandas read_csv function to read the csv file into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# path to the csv file\n",
    "csv_file = './labeled_tracks.csv'\n",
    "\n",
    "# transform the csv file to a DF\n",
    "train_data = pd.read_csv(csv_file, encoding='utf_8', \n",
    "                       header=0)\n",
    "\n",
    "# add features as empty columns\n",
    "for f in features:\n",
    "    train_data[f] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset contains 163 tracks.\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 163 entries, 0 to 162\n",
      "Data columns (total 14 columns):\n",
      "song                163 non-null object\n",
      "artist              163 non-null object\n",
      "category            163 non-null object\n",
      "acousticness        0 non-null float64\n",
      "danceability        0 non-null float64\n",
      "energy              0 non-null float64\n",
      "instrumentalness    0 non-null float64\n",
      "key                 0 non-null float64\n",
      "loudness            0 non-null float64\n",
      "mode                0 non-null float64\n",
      "speechiness         0 non-null float64\n",
      "tempo               0 non-null float64\n",
      "time_signature      0 non-null float64\n",
      "valence             0 non-null float64\n",
      "dtypes: float64(11), object(3)\n",
      "memory usage: 19.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# review the result\n",
    "print (\"Training dataset contains {} tracks.\"\n",
    "       .format(len(train_data)))\n",
    "print \n",
    "print train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add features to the training DF\n",
    "train_df = add_features_from_echonest(train_data, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 143 entries, 0 to 162\n",
      "Data columns (total 14 columns):\n",
      "song                143 non-null object\n",
      "artist              143 non-null object\n",
      "category            143 non-null object\n",
      "acousticness        143 non-null float64\n",
      "danceability        143 non-null float64\n",
      "energy              143 non-null float64\n",
      "instrumentalness    143 non-null float64\n",
      "key                 143 non-null float64\n",
      "loudness            143 non-null float64\n",
      "mode                143 non-null float64\n",
      "speechiness         141 non-null float64\n",
      "tempo               143 non-null float64\n",
      "time_signature      143 non-null float64\n",
      "valence             143 non-null float64\n",
      "dtypes: float64(11), object(3)\n",
      "memory usage: 16.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# get info about data\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to change the order of columns in the training set to keep it consistent with the test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acousticness',\n",
       " 'danceability',\n",
       " 'energy',\n",
       " 'instrumentalness',\n",
       " 'key',\n",
       " 'loudness',\n",
       " 'mode',\n",
       " 'speechiness',\n",
       " 'tempo',\n",
       " 'time_signature',\n",
       " 'valence',\n",
       " u'song',\n",
       " u'artist',\n",
       " u'category']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = train_df.columns.tolist()\n",
    "cols = cols[3:] + cols[:3]\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# change order of columns\n",
    "train_df = train_df.ix[:, cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 143 entries, 0 to 162\n",
      "Data columns (total 14 columns):\n",
      "acousticness        143 non-null float64\n",
      "danceability        143 non-null float64\n",
      "energy              143 non-null float64\n",
      "instrumentalness    143 non-null float64\n",
      "key                 143 non-null float64\n",
      "loudness            143 non-null float64\n",
      "mode                143 non-null float64\n",
      "speechiness         141 non-null float64\n",
      "tempo               143 non-null float64\n",
      "time_signature      143 non-null float64\n",
      "valence             143 non-null float64\n",
      "song                143 non-null object\n",
      "artist              143 non-null object\n",
      "category            143 non-null object\n",
      "dtypes: float64(11), object(3)\n",
      "memory usage: 16.8+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the test set, I convert dtype in columns \"key\", \"mode\", and \"time_signature\" to integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 143 entries, 0 to 162\n",
      "Data columns (total 14 columns):\n",
      "acousticness        143 non-null float64\n",
      "danceability        143 non-null float64\n",
      "energy              143 non-null float64\n",
      "instrumentalness    143 non-null float64\n",
      "key                 143 non-null int64\n",
      "loudness            143 non-null float64\n",
      "mode                143 non-null int64\n",
      "speechiness         141 non-null float64\n",
      "tempo               143 non-null float64\n",
      "time_signature      143 non-null int64\n",
      "valence             143 non-null float64\n",
      "song                143 non-null object\n",
      "artist              143 non-null object\n",
      "category            143 non-null object\n",
      "dtypes: float64(8), int64(3), object(3)\n",
      "memory usage: 16.8+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df[['key', 'mode', 'time_signature']] = train_df[['key', 'mode', 'time_signature']].astype(int)\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a quick glimpse of data, I save both DataFrames on disk in HDF5 format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save test df \n",
    "test_df.to_hdf('music_data.h5', 'test_df', min_itemsize = {'values': 50})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save training df\n",
    "train_df.to_hdf('music_data.h5', 'train_df', min_itemsize = {'values': 50})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.io.pytables.HDFStore'>\n",
      "File path: music_data.h5\n",
      "/test_df             frame        (shape->[536,13])\n",
      "/train_df            frame        (shape->[143,12])\n"
     ]
    }
   ],
   "source": [
    "# check the result\n",
    "print pd.HDFStore('music_data.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data overview  \n",
    "  \n",
    "I have two datasets with track attributes data from the Echo Nest API. Next step is to take a look at what I'm working with.\n",
    "### Test data overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 669 tracks in the xml file.\n",
      "133 tracks have no data available in the Echo Nest API.\n",
      "We are left with 536 tracks to use as test data.\n",
      "\n",
      "Below is a random sample of the dataset.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.53</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0</td>\n",
       "      <td>-10.61</td>\n",
       "      <td>0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>130.39</td>\n",
       "      <td>4</td>\n",
       "      <td>0.39</td>\n",
       "      <td>Junip</td>\n",
       "      <td>Without you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.23</td>\n",
       "      <td>5</td>\n",
       "      <td>-13.66</td>\n",
       "      <td>1</td>\n",
       "      <td>0.04</td>\n",
       "      <td>81.62</td>\n",
       "      <td>4</td>\n",
       "      <td>0.38</td>\n",
       "      <td>Moby</td>\n",
       "      <td>The Sky Is Broken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4</td>\n",
       "      <td>-13.84</td>\n",
       "      <td>1</td>\n",
       "      <td>0.04</td>\n",
       "      <td>104.98</td>\n",
       "      <td>4</td>\n",
       "      <td>0.38</td>\n",
       "      <td>Phoebe Killdeer and the Short Straws</td>\n",
       "      <td>Let Me</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     acousticness  danceability  energy  instrumentalness  key  loudness  \\\n",
       "115          0.53          0.68    0.77              0.83    0    -10.61   \n",
       "355          0.73          0.81    0.37              0.23    5    -13.66   \n",
       "157          0.37          0.66    0.34              0.01    4    -13.84   \n",
       "\n",
       "     mode  speechiness  tempo  time_signature  valence  \\\n",
       "115     0         0.03 130.39               4     0.39   \n",
       "355     1         0.04  81.62               4     0.38   \n",
       "157     1         0.04 104.98               4     0.38   \n",
       "\n",
       "                                   artist               song  \n",
       "115                                 Junip        Without you  \n",
       "355                                  Moby  The Sky Is Broken  \n",
       "157  Phoebe Killdeer and the Short Straws             Let Me  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (\"There are {} tracks in the xml file.\\n\"\n",
    "       \"{} tracks have no data available \"\n",
    "       \"in the Echo Nest API.\\n\"\n",
    "       \"We are left with {} tracks to use as test data.\\n\"\n",
    "       .format(len(test_data), \n",
    "               (len(test_data) - len(test_df)),\n",
    "              len(test_df)))\n",
    "print \"Below is a random sample of the dataset.\"\n",
    "test_df.sample(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 163 tracks in the csv file.\n",
      "20 tracks have no data available in the Echo Nest API.\n",
      "We are left with 143 tracks to use as training data.\n",
      "\n",
      "Below is a random sample of the dataset.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "      <th>song</th>\n",
       "      <th>artist</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "      <td>-8.69</td>\n",
       "      <td>1</td>\n",
       "      <td>0.04</td>\n",
       "      <td>84.39</td>\n",
       "      <td>4</td>\n",
       "      <td>0.21</td>\n",
       "      <td>Skinny Love</td>\n",
       "      <td>Birdy</td>\n",
       "      <td>ballet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "      <td>-3.91</td>\n",
       "      <td>1</td>\n",
       "      <td>0.04</td>\n",
       "      <td>148.13</td>\n",
       "      <td>4</td>\n",
       "      <td>0.46</td>\n",
       "      <td>Light of love</td>\n",
       "      <td>Music Go Music</td>\n",
       "      <td>cycling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9</td>\n",
       "      <td>-4.82</td>\n",
       "      <td>1</td>\n",
       "      <td>0.07</td>\n",
       "      <td>122.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.88</td>\n",
       "      <td>Lost on me</td>\n",
       "      <td>Peace</td>\n",
       "      <td>cycling</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     acousticness  danceability  energy  instrumentalness  key  loudness  \\\n",
       "4            0.96          0.37    0.28              0.00    4     -8.69   \n",
       "145          0.03          0.50    0.69              0.00    7     -3.91   \n",
       "49           0.01          0.62    0.93              0.00    9     -4.82   \n",
       "\n",
       "     mode  speechiness  tempo  time_signature  valence           song  \\\n",
       "4       1         0.04  84.39               4     0.21    Skinny Love   \n",
       "145     1         0.04 148.13               4     0.46  Light of love   \n",
       "49      1         0.07 122.00               4     0.88     Lost on me   \n",
       "\n",
       "             artist category  \n",
       "4             Birdy   ballet  \n",
       "145  Music Go Music  cycling  \n",
       "49            Peace  cycling  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (\"There are {} tracks in the csv file.\\n\"\n",
    "       \"{} tracks have no data available \"\n",
    "       \"in the Echo Nest API.\\n\"\n",
    "       \"We are left with {} tracks to use as training data.\\n\"\n",
    "       .format(len(train_data), \n",
    "               (len(train_data) - len(train_df)),\n",
    "              len(train_df)))\n",
    "print \"Below is a random sample of the dataset.\"\n",
    "train_df.sample(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracks in the dataset belong to 3 classes: ballet, cycling, yoga.\n",
      "49 tracks represent 'ballet' class.\n",
      "45 tracks represent 'cycling' class.\n",
      "49 tracks represent 'yoga' class.\n"
     ]
    }
   ],
   "source": [
    "# list of categories\n",
    "categories = list(pd.unique(train_df.category.ravel()))\n",
    "\n",
    "print (\"Tracks in the dataset belong \" \n",
    "       \"to {} classes: {}.\"\n",
    "       .format(len(categories), \", \".join(categories)))\n",
    "\n",
    "# count tracks in each category\n",
    "cat_count = pd.value_counts(train_df.category.ravel())\n",
    "\n",
    "# print categories\n",
    "for category in categories:\n",
    "    print (\"{} tracks represent \\'{}\\' class.\"\n",
    "           .format(cat_count[category], category))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "In this notebook I described data gathering and cleaning process for further analysis. I parsed iTunes music library xml file to create a dataframe as a test dataset. I also transformed the csv file with labeled tracks to a dataframe as a training set. Using the Echo Nest API I got track attributes for both sets.\n",
    "\n",
    "As a result of the above manipulations I created two pandas dataframes: \n",
    "* train dataframe contains 143 tracks labeled with one of the three classes — \"ballet\", \"cycling\", \"yoga\";\n",
    "* test dataframe contains 536 non-labeled tracks. \n",
    "\n",
    "Each set has 11 music attributes for every song which I'm going to analyse in the following posts.\n",
    "\n",
    "The next step in my analysis is to visualize both datasets and examine track attributes, which I cover in the next post [02_Data_visualisation](http://localhost:8888/notebooks/02_Data_Visualisation.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
